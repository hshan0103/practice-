{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from  datetime import datetime, timedelta\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "#LabelEncoder, StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np, pandas as pd\n",
    "import matplotlib.pyplot as plot \n",
    "import sklearn\n",
    "import lightgbm as lgb\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_df(prev_last, pred_period, is_train=True):\n",
    "    \n",
    "    cal_cat_cols = ['weekday', 'event_name_1', 'event_type_1', 'event_name_2', 'event_type_2']\n",
    "    sales_cat_cols = ['item_id', 'dept_id', 'cat_id', 'store_id', 'state_id']\n",
    "    price_cat_cols = ['store_id', 'item_id']\n",
    "    \n",
    "    calendars = pd.read_csv('/Users/hshan/Downloads/M5/calendar.csv')\n",
    "    sales = pd.read_csv('/Users/hshan/Downloads/M5/sales_train_validation.csv')\n",
    "    prices = pd.read_csv('/Users/hshan/Downloads/M5/sell_prices.csv')\n",
    "    \n",
    "    if not is_train:\n",
    "        for i in range((prev_last+1), (prev_last+pred_period+1)):\n",
    "            f_string = f'd_{i}'\n",
    "            sales[f_string] = pd.Series()\n",
    "    \n",
    "    ind_var = ['id'] + sales_cat_cols\n",
    "    val_var = [col for col in sales.columns if col.startswith('d_')]\n",
    "    df = pd.melt(sales, id_vars = ind_var, value_vars = val_var, var_name = 'd', value_name='sales')\n",
    "    df = df.merge(calendars, on = 'd', copy = False)\n",
    "    df = df.merge(prices, on = [\"store_id\", \"item_id\", \"wm_yr_wk\"], copy = False)\n",
    "    \n",
    "    cat_cols = cal_cat_cols + sales_cat_cols\n",
    "    label_encoder = LabelEncoder()\n",
    "    for col in cat_cols:\n",
    "        df[col] = df[col].fillna('').astype('category')\n",
    "        df[col] = label_encoder.fit_transform(df[col])\n",
    "\n",
    "    unused_cols = ['wm_yr_wk', 'weekday','store_id']\n",
    "    \n",
    "    df.drop(unused_cols, inplace = True, axis = 1)\n",
    "    \n",
    "    return (df)\n",
    "\n",
    "def lag_features(df):\n",
    "    '''max lag should not be exceeding 57 in this case'''\n",
    "    num = [1,7,28]\n",
    "    lags = num\n",
    "    windows = num\n",
    "    lag_cols = [f'lag_{lag}' for lag in lags]\n",
    "    \n",
    "\n",
    "    for lag, lag_col in zip(lags, lag_cols):\n",
    "        df[lag_col] = df[['id','sales']].groupby('id')['sales'].shift(lag)\n",
    "        \n",
    "    for window in windows:\n",
    "        for lag, lag_col in zip(lags, lag_cols):\n",
    "            mean_col = f'mean_{lag}_{window}'\n",
    "            df[mean_col] = df[['id',lag_col]].groupby('id')[lag_col].transform(lambda x: x.rolling(window).mean())\n",
    "    \n",
    "    return (df)\n",
    "\n",
    "def submission(result_df):\n",
    "    '''result_df is the resulted dataframe from for looping in predicting, \n",
    "    it includes 56 samples before the first day of the prediction d_1914'''\n",
    "    sub_df = df.loc[pd.to_datetime(df.date)>= first_day,['id','d','sales']]\n",
    "    val_df = sub_df.loc[(pd.to_datetime(df.date)>= first_day)& (pd.to_datetime(df.date)< first_day+timedelta(days=28))]\n",
    "    eval_df = sub_df.loc[pd.to_datetime(df.date)>= (first_day+timedelta(days=28))]\n",
    "    \n",
    "    col_v= list(val_df['d'].unique())\n",
    "    col_e= list(eval_df['d'].unique())\n",
    "    \n",
    "    f_cols =[]\n",
    "    for i in range(1, 29):\n",
    "        f_col = f'F{i}'\n",
    "        f_cols.append(f_col)\n",
    "    \n",
    "    val_df = val_df.set_index([\"id\", \"d\" ]).unstack()['sales'][col_v].reset_index()\n",
    "    eval_df = eval_df.set_index([\"id\", \"d\" ]).unstack()['sales'][col_e].reset_index()\n",
    "    \n",
    "    val_df.columns=['id'] + f_cols\n",
    "    eval_df.columns=['id'] + f_cols\n",
    "    \n",
    "    for i in range(0,len(eval_df)):\n",
    "        eval_df['id'][i] = eval_df['id'][i].replace('validation','evaluation')\n",
    "        final_sub = pd.concat([val_df, eval_df])\n",
    "        \n",
    "    return (final_sub)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_period = 56\n",
    "train_start = 1\n",
    "train_last = 1913\n",
    "test_start = train_last + 1\n",
    "test_last  = train_last + pred_period\n",
    "pred_start = test_last + 1\n",
    "pred_last = test_last + pred_period\n",
    "seed = 1231\n",
    "\n",
    "removed_cols = ['id', 'date', 'sales', 'd', 'wm_yr_wk', 'weekday']\n",
    "categorical_cols = ['wday','event_name_1', 'event_type_1', 'event_name_2', 'event_type_2'] + \\\n",
    "    ['item_id', 'dept_id', 'cat_id', 'store_id', 'state_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = load_df(train_last, pred_period, is_train=True)\n",
    "df = lag_features(df)\n",
    "\n",
    "df.dropna(inplace=True)\n",
    "y_target = df['sales']\n",
    "\n",
    "df_cols = list(df.columns)\n",
    "x_features =[]\n",
    "for feature in df_cols:\n",
    "    if feature not in removed_cols:\n",
    "        x_features.append(feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param = {\n",
    "    \"objective\" : \"poisson\",\n",
    "    \"metric\" :\"rmse\",\n",
    "    'boosting_type' : 'gbdt',\n",
    "    \"force_row_wise\" : True,\n",
    "    \"learning_rate\" : 0.075,\n",
    "    #\"sub_feature\" : 0.8,\n",
    "    \"sub_row\" : 0.75,\n",
    "    \"bagging_freq\" : 1,\n",
    "    \"lambda_l2\" : 1.5,\n",
    "    \"lambda_l1\" : 0.5,\n",
    "    \"nthread\" : 5,\n",
    "    \"metric\": \"rmse\",\n",
    "    'verbosity': -1,\n",
    "    'num_iterations' : 2000,\n",
    "    'num_leaves': 200,\n",
    "    \"min_data_in_leaf\": 200,\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbm_train_data = lgb.Dataset(df[x_features], label = df['sales'])\n",
    "# model = lgb.train(param, train_set=lgbm_train_data, valid_sets=lgbm_valid_data, categorical_feature=categorical_cols, \n",
    "#             verbose_eval=100, early_stopping_rounds=120)\n",
    "# model = lgb.train(param, train_set=lgbm_train_data, categorical_feature=categorical_cols)\n",
    "model = lgb.train(param, train_set=lgbm_train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = '/Users/hshan/Kaggle/model.sav'\n",
    "joblib.dump(model, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = joblib.load('/Users/hshan/Kaggle/model_no_val.sav')\n",
    "df = load_df(train_last, pred_period, is_train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_day = datetime(2016, 4, 25)\n",
    "for delta in range(0, pred_period):\n",
    "    predict_day = first_day + timedelta(days = delta)\n",
    "    predict_df = df.loc[(pd.to_datetime(df.date) <= predict_day) & (pd.to_datetime(df.date) >= predict_day - timedelta(days=57))]\n",
    "    \n",
    "    predict_df = lag_features(predict_df)\n",
    "    \n",
    "    predict_df = predict_df.loc[pd.to_datetime(predict_df.date) == predict_day]\n",
    "    predict_df= predict_df[x_features]\n",
    "    result = model.predict(predict_df)\n",
    "    \n",
    "    df.loc[pd.to_datetime(df.date)==predict_day,'sales'] = result\n",
    "    del predict_df\n",
    "    print(predict_day)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission(df).to_csv('/Users/hshan/Downloads/M5/model_sub.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
