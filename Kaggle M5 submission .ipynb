{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "from  datetime import datetime, timedelta\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import pandas as pd\n",
    "import numpy as np, pandas as pd\n",
    "import matplotlib.pyplot as plot \n",
    "import random\n",
    "import lightgbm as lgb\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_df():\n",
    "    \n",
    "    cal_cat_cols = ['weekday', 'event_name_1', 'event_type_1', 'event_name_2', 'event_type_2']\n",
    "    sales_cat_cols = ['item_id', 'dept_id', 'cat_id', 'store_id', 'state_id']\n",
    "    price_cat_cols = ['store_id', 'item_id']\n",
    "    \n",
    "    calendars = pd.read_csv('/Users/hshan/Downloads/M5/calendar.csv')\n",
    "    sales = pd.read_csv('/Users/hshan/Downloads/M5/sales_train_validation.csv')\n",
    "    prices = pd.read_csv('/Users/hshan/Downloads/M5/sell_prices.csv')\n",
    "    \n",
    "    n=1913 + 56\n",
    "    for i in range(1914,(n+1)):\n",
    "        col = f'd_{i}'\n",
    "        sales[col] = pd.Series()\n",
    "    \n",
    "    ind_var = ['id'] + sales_cat_cols\n",
    "    val_var = [col for col in sales.columns if col.startswith('d_')]\n",
    "    df = pd.melt(sales, id_vars = ind_var, value_vars = val_var, var_name = 'd', value_name='sales')\n",
    "    df = df.merge(calendars, on = 'd', copy = False)\n",
    "    df = df.merge(prices, on = [\"store_id\", \"item_id\", \"wm_yr_wk\"], copy = False)\n",
    "    \n",
    "    cat_cols = cal_cat_cols + sales_cat_cols\n",
    "    label_encoder = LabelEncoder()\n",
    "    for col in cat_cols:\n",
    "        df[col] = df[col].fillna('').astype('category')\n",
    "        df[col] = label_encoder.fit_transform(df[col])\n",
    "\n",
    "    unused_cols = ['date','wm_yr_wk', 'weekday']\n",
    "    \n",
    "    df.drop(unused_cols, inplace = True, axis = 1)\n",
    "    \n",
    "    return (df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lag_features(df):\n",
    "    '''max lag should not be exceeding 57 in this case'''\n",
    "    num = [1,7,28]\n",
    "    lags = num\n",
    "    windows = num\n",
    "    lag_cols = [f'lag_{lag}' for lag in lags]\n",
    "    \n",
    "\n",
    "    for lag, lag_col in zip(lags, lag_cols):\n",
    "        df[lag_col] = df[['id','sales']].groupby('id')['sales'].shift(lag)\n",
    "        \n",
    "    for window in windows:\n",
    "        for lag, lag_col in zip(lags, lag_cols):\n",
    "            mean_col = f'mean_{lag}_{window}'\n",
    "            df[mean_col] = df[['id',lag_col]].groupby('id')[lag_col].transform(lambda x: x.rolling(window).mean())\n",
    "    \n",
    "\n",
    "    return (df)\n",
    "\n",
    "categorical_cols = ['weekday', 'event_name_1', 'event_type_1', 'event_name_2', 'event_type_2'] + \\\n",
    "    ['item_id', 'dept_id', 'cat_id', 'store_id', 'state_id']\n",
    "removed_cols = ['id', 'date', 'sales', 'd', 'wm_yr_wk', 'weekday']\n",
    "\n",
    "def pca(x_features_df, n_components):\n",
    "    pca = PCA(n_components)\n",
    "    pca_cols = []\n",
    "    for i in range(n_components):\n",
    "        pca_col = f'pc_{i+1}'\n",
    "        pca_cols.append(pca_col)\n",
    "    p_components = pca.fit_transform(x_features_df)\n",
    "    pca_features_df = pd.DataFrame(data = p_components, columns = pca_cols)\n",
    "    \n",
    "    return(pca_features_df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = load_df()\n",
    "df = lag_features(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = []\n",
    "for i in range(1942, 1970):\n",
    "    col = f'd_{i}'\n",
    "    cols.append(col)\n",
    "val_df = pd.DataFrame(df.loc[df['d'].isin(cols)])\n",
    "val_df.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cols = list(val_df.columns)\n",
    "x_features =[]\n",
    "for feature in df_cols:\n",
    "    if feature not in removed_cols:\n",
    "        x_features.append(feature)\n",
    "n_components = int(0.65*(len(df_cols)-2))\n",
    "pca_features_df = pca(val_df[x_features], n_components)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = joblib.load('/Users/hshan/model.sav')\n",
    "result = model.predict(pca_features_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df=pd.DataFrame(val_df[['id','d']])\n",
    "result_df['sales'] = result\n",
    "df_unmelted = result_df.pivot(index='id', columns='d')\n",
    "df_unmelted = df_unmelted['sales'].reset_index()\n",
    "df_unmelted.columns.name = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_cols =[]\n",
    "for i in range(0, 28):\n",
    "    f_col = f'F{i+1}'\n",
    "    f_cols.append(f_col)\n",
    "df_cols = ['id'] + f_cols\n",
    "df_unmelted.columns = df_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,len(df_unmelted)):\n",
    "    df_unmelted['id'][i] = df_unmelted['id'][i].replace('validation','evaluation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_unmelted' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-77-9f7e4f9128e0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf_unmelted\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/Users/hshan/Downloads/M5/submission1.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'df_unmelted' is not defined"
     ]
    }
   ],
   "source": [
    "df_unmelted.to_csv('/Users/hshan/Downloads/M5/submission1.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
